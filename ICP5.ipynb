{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ICP5.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOd7j3CjI7R0ih3dAzD5O/W",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/brucker3/KDM_spring2021/blob/main/ICP5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L68tMoXgNihH",
        "outputId": "ddb29cb9-1f25-4bdd-ae57-94d4827bd715"
      },
      "source": [
        "# intsall spark and importing necessry packages \n",
        "!pip install pyspark\n",
        "from __future__ import print_function\n",
        "from pyspark import SparkConf, SparkContext\n",
        "from pyspark.ml.feature import HashingTF, IDF, Tokenizer\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml.feature import NGram\n",
        "from pyspark.ml.feature import Word2Vec\n",
        "\n",
        "# creating spark session\n",
        "spark = SparkSession.builder.appName(\"ICP5\").getOrCreate()\n",
        "\n",
        "\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyspark\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/27/67/5158f846202d7f012d1c9ca21c3549a58fd3c6707ae8ee823adcaca6473c/pyspark-3.0.2.tar.gz (204.8MB)\n",
            "\u001b[K     |████████████████████████████████| 204.8MB 39kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.9\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/b6/6a4fb90cd235dc8e265a6a2067f2a2c99f0d91787f06aca4bcf7c23f3f80/py4j-0.10.9-py2.py3-none-any.whl (198kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 48.5MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.0.2-py2.py3-none-any.whl size=205186687 sha256=2ae64b1d956d9cd1eadc2c9e876761d250068050fa8a1fa8c85e7f33c1462f38\n",
            "  Stored in directory: /root/.cache/pip/wheels/8b/09/da/c1f2859bcc86375dc972c5b6af4881b3603269bcc4c9be5d16\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9 pyspark-3.0.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iXCY1T_7Zcr1",
        "outputId": "5ee9c3d3-4bd5-421c-94c0-2446357e6f64"
      },
      "source": [
        "# https://sparkbyexamples.com/spark/spark-read-text-file-rdd-dataframe/\n",
        "# https://colab.research.google.com/github/computationalcore/introduction-to-python/blob/master/notebooks/4-files/PY0101EN-4-1-ReadFile.ipynb#scrollTo=ArrqzEmQx2_M\n",
        "# read in of all 5 txt files \n",
        "# I tried to do this a cleaner way but spark kept skipping over some of the files \n",
        "txt1 = \"../content/txt1.txt\"\n",
        "txt2 = \"../content/txt2.txt\"\n",
        "txt3 = \"../content/txt3.txt\"\n",
        "txt4 = \"../content/txt4.txt\"\n",
        "txt5 = \"../content/txt5.txt\"\n",
        "# opening and converting read in files to use able form \n",
        "txt1 = open(txt1, \"r\")\n",
        "txt2 = open(txt2, \"r\")\n",
        "txt3 = open(txt3, \"r\")\n",
        "txt4 = open(txt4, \"r\")\n",
        "txt5 = open(txt5, \"r\")\n",
        "\n",
        "# creating spark dataframe wiht the input data. \n",
        "sentenceData = spark.createDataFrame([\n",
        "        (0, txt1.read()),\n",
        "        (1, txt2.read()),\n",
        "        (2, txt3.read()),\n",
        "        (3, txt4.read()),\n",
        "        (4, txt5.read())\n",
        "    ], [\"label\", \"sentence\"])\n",
        "\n",
        "# cheking data type and that df is set up corretly \n",
        "type(sentenceData)\n",
        "sentenceData.head(5)\n"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(label=0, sentence='When you ask Americans a binary question about reopening schools, support for reopening appears high. For example, a Jan. 28-30 poll by RMG Research for Just the News found that 53 percent of registered voters thought schools in their area should be open for in-person learning, while just 31 percent thought they should remain closed. And according to a Feb. 12-15 Morning Consult/Politico survey, 57 percent of registered voters thought it was a good idea for K-12 schools to reopen in fall 2021, while just 26 percent thought it was a bad idea.\\n\\nAdd an option for hybrid learning, however, and the nation is more ambivalent. According to a YouGov/HuffPost poll conducted Feb. 3-7, adults were evenly divided among the three options. Twenty-seven percent thought schools should be completely reopened, 29 percent thought schools should be partially reopened and 30 percent thought they should be closed or online-only.\\n'),\n",
              " Row(label=1, sentence=\"So a new coach is in. That's a start for the team with the league's worst record. But D'Angelo Russell is out until near the NBA's March 25 trade deadline with a knee injury. Karl-Anthony Towns has had a deeply difficult year, losing his mother and many family members to the pandemic, catching COVID-19 himself and getting hit by a drunk driver.\\n\\nThe Timberwolves built around their two young stars, but the duo has gotten just 90 minutes on the floor this season. Rudy Gobert and Donovan Mitchell of the 24-6 Utah Jazz, for instance, have logged close to 600.\\n\"),\n",
              " Row(label=2, sentence=\"Whether it's in the first round or the sixth round, finding value above expectation in the NFL draft can significantly alter the landscape of a franchise. It is easier to do that with a wealth of draft capital, of course, but it's important how much a team can get from its draft picks relative to where they were taken rather than just blindly adding together all the production from the class.\\n\\nIf Player X and Player Y have similar seasons, the production from Player Y, taken in the sixth round, is much more valuable than the production a team gets from first-round-pick Player X.\\n\"),\n",
              " Row(label=3, sentence=\"This is not everyday pizza. It's not every-week pizza. It might not even be every-month, if you want to live to a reasonable age. But damn, is it good pizza. So good that it's worth a trip to Detroit just to taste it. So good that it's worth devoting months of time, weeks of research, and dozens and dozens of experiments to developing a recipe to duplicate it at home. So that's exactly what I did. Here's what I found.\\n\"),\n",
              " Row(label=4, sentence='But in 2002, when a friend suggested Loh apply for an open position as a grader with the team, he hesitated. “I had never thought to apply before,” Loh said. “Not because I didn’t want to. But because I thought there are better people out there.”\\n\\nHe eventually agreed, and by the end of the team’s June 2002 training program, he’d made an impression. “Somehow I got voted best lecturer,” he said. In 2013 the Mathematical Association of America, which coordinates the team, asked Loh to become the head coach. He accepted, and two years later the U.S. achieved a top ranking in the IMO for the first time in 21 years.\\n')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nm35o18iiABP"
      },
      "source": [
        "# tokenizer to set up for IDF calculation \n",
        "tokenizer = Tokenizer(inputCol=\"sentence\", outputCol=\"words\")\n",
        "wordsData = tokenizer.transform(sentenceData)\n",
        "\n",
        "\n",
        "\n",
        "# applying tf on the words data\n",
        "hashingTF = HashingTF(inputCol=\"words\", outputCol=\"rawFeatures\", numFeatures=20)\n",
        "featurizedData = hashingTF.transform(wordsData)\n",
        "# alternatively, CountVectorizer can also be used to get term frequency vectors\n",
        "\n",
        "\n",
        "# calculating the IDF\n",
        "idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\")\n",
        "idfModel = idf.fit(featurizedData)\n",
        "rescaledData = idfModel.transform(featurizedData)\n",
        "\n",
        "\n",
        "#displaying the results\n",
        "rescaledData.select(\"label\", \"features\").show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}